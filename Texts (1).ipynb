{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rupo.api import Engine\n",
    "engine = Engine(language=\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): markovify in /opt/conda/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): unidecode in /opt/conda/lib/python3.5/site-packages (from markovify)\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "И песня, и стих это бомба и знамя, и голос подают, - Как будто в жены их готовим скоморохам.\n",
      "И то же солнце ходит надо мной, Но и я у ваших ног положить букеты и венок.\n",
      "это друг мой милый.\n",
      "И дальше, к деревне, быт без движеньица живут, как и в жизни был мастак.\n",
      "Я раньше вас почти не чувствуя печали.\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "# Get raw text as string.\n",
    "with open(\"corpus.txt\",encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Build the model.\n",
    "text_model = markovify.Text(text)\n",
    "\n",
    "# Print five randomly-generated sentences\n",
    "for i in range(5):\n",
    "    print(text_model.make_sentence())\n",
    "\n",
    "# Print three randomly-generated sentences of no more than 140 characters\n",
    "for i in range(3):\n",
    "    print(text_model.make_short_sentence(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "with open('corpus.txt', 'r', encoding='utf-8') as f:\n",
    "    text=f.read()\n",
    "vocab = sorted(set(text))\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    \n",
    "    characters_per_batch = n_seqs * n_steps\n",
    "    n_batches = len(arr)//characters_per_batch\n",
    "    \n",
    "    arr = arr[:n_batches * characters_per_batch]\n",
    "    \n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        y = np.zeros_like(x)\n",
    "        y[:, :-1], y[:, -1] = x[:, 1:], x[:, 0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[115 142 143 131 129]\n",
      " [160  29   1 113 143]\n",
      " [  2 133 142 134 138]\n",
      " [145 137 133 148 141]\n",
      " [143 131 157   2 144]]\n",
      "\n",
      "y\n",
      " [[142 143 131 129   2]\n",
      " [ 29   1 113 143 142]\n",
      " [133 142 134 138  11]\n",
      " [137 133 148 141 129]\n",
      " [131 157   2 144 140]]\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)\n",
    "print('x\\n', x[:5, :5])\n",
    "print('\\ny\\n', y[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    \n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    x = tf.reshape(seq_output, [-1, in_size])\n",
    "    \n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((in_size, out_size), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    out = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "    y_reshaped = tf.reshape(y_one_hot, logits.get_shape())\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps)\n",
    "\n",
    "        cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "\n",
    "        x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
    "        \n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        \n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100        # Размер пакета\n",
    "num_steps = 100         # Шагов в пакете\n",
    "lstm_size = 512       # Количество LSTM юнитов в скрытом слое\n",
    "num_layers = 2          # Количество LSTM слоев\n",
    "learning_rate = 0.001   # Скорость обучения\n",
    "keep_prob = 0.5         # Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10...  Training Step: 1...  Training loss: 5.1306...  1.0671 sec/batch\n",
      "checkpoints/i1_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 2...  Training loss: 5.0567...  0.9667 sec/batch\n",
      "checkpoints/i2_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 3...  Training loss: 4.5322...  0.8716 sec/batch\n",
      "checkpoints/i3_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 4...  Training loss: 6.1852...  0.8556 sec/batch\n",
      "checkpoints/i4_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 5...  Training loss: 4.7133...  0.8688 sec/batch\n",
      "checkpoints/i5_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 6...  Training loss: 4.3152...  0.8601 sec/batch\n",
      "checkpoints/i6_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 7...  Training loss: 4.2149...  0.8539 sec/batch\n",
      "checkpoints/i7_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 8...  Training loss: 4.0756...  0.8680 sec/batch\n",
      "checkpoints/i8_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 9...  Training loss: 3.9677...  0.8657 sec/batch\n",
      "checkpoints/i9_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 10...  Training loss: 3.8526...  0.8724 sec/batch\n",
      "checkpoints/i10_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 11...  Training loss: 3.7862...  0.9057 sec/batch\n",
      "checkpoints/i11_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 12...  Training loss: 3.7257...  0.8587 sec/batch\n",
      "checkpoints/i12_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 13...  Training loss: 3.7263...  0.8554 sec/batch\n",
      "checkpoints/i13_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 14...  Training loss: 3.6925...  0.8570 sec/batch\n",
      "checkpoints/i14_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 15...  Training loss: 3.7248...  0.8589 sec/batch\n",
      "checkpoints/i15_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 16...  Training loss: 3.7069...  0.8866 sec/batch\n",
      "checkpoints/i16_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 17...  Training loss: 3.6908...  0.9037 sec/batch\n",
      "checkpoints/i17_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 18...  Training loss: 3.6549...  0.8475 sec/batch\n",
      "checkpoints/i18_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 19...  Training loss: 3.6550...  0.8480 sec/batch\n",
      "checkpoints/i19_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 20...  Training loss: 3.6148...  0.8579 sec/batch\n",
      "checkpoints/i20_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 21...  Training loss: 3.5913...  0.8789 sec/batch\n",
      "checkpoints/i21_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 22...  Training loss: 3.5856...  0.8686 sec/batch\n",
      "checkpoints/i22_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 23...  Training loss: 3.5482...  0.9000 sec/batch\n",
      "checkpoints/i23_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 24...  Training loss: 3.5989...  0.8563 sec/batch\n",
      "checkpoints/i24_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 25...  Training loss: 3.5756...  0.8641 sec/batch\n",
      "checkpoints/i25_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 26...  Training loss: 3.5537...  0.8752 sec/batch\n",
      "checkpoints/i26_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 27...  Training loss: 3.5905...  0.8658 sec/batch\n",
      "checkpoints/i27_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 28...  Training loss: 3.5614...  0.8592 sec/batch\n",
      "checkpoints/i28_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 29...  Training loss: 3.5508...  0.9076 sec/batch\n",
      "checkpoints/i29_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 30...  Training loss: 3.5408...  0.8920 sec/batch\n",
      "checkpoints/i30_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 31...  Training loss: 3.5130...  0.8596 sec/batch\n",
      "checkpoints/i31_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 32...  Training loss: 3.5321...  0.8678 sec/batch\n",
      "checkpoints/i32_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 33...  Training loss: 3.5431...  0.8852 sec/batch\n",
      "checkpoints/i33_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 34...  Training loss: 3.5449...  0.8774 sec/batch\n",
      "checkpoints/i34_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 35...  Training loss: 3.5130...  0.8570 sec/batch\n",
      "checkpoints/i35_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 36...  Training loss: 3.5369...  0.8666 sec/batch\n",
      "checkpoints/i36_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 37...  Training loss: 3.5159...  0.8528 sec/batch\n",
      "checkpoints/i37_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 38...  Training loss: 3.5131...  0.8677 sec/batch\n",
      "checkpoints/i38_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 39...  Training loss: 3.5302...  0.8748 sec/batch\n",
      "checkpoints/i39_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 40...  Training loss: 3.5116...  0.8738 sec/batch\n",
      "checkpoints/i40_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 41...  Training loss: 3.5176...  0.8615 sec/batch\n",
      "checkpoints/i41_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 42...  Training loss: 3.5403...  0.8667 sec/batch\n",
      "checkpoints/i42_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 43...  Training loss: 3.5499...  0.8525 sec/batch\n",
      "checkpoints/i43_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 44...  Training loss: 3.5590...  0.8573 sec/batch\n",
      "checkpoints/i44_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 45...  Training loss: 3.5876...  0.8580 sec/batch\n",
      "checkpoints/i45_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 46...  Training loss: 3.6303...  0.8602 sec/batch\n",
      "checkpoints/i46_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 47...  Training loss: 3.6038...  0.8550 sec/batch\n",
      "checkpoints/i47_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 48...  Training loss: 3.5927...  0.8519 sec/batch\n",
      "checkpoints/i48_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 49...  Training loss: 3.5575...  0.8555 sec/batch\n",
      "checkpoints/i49_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 50...  Training loss: 3.5431...  0.8605 sec/batch\n",
      "checkpoints/i50_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 51...  Training loss: 3.4939...  0.8480 sec/batch\n",
      "checkpoints/i51_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 52...  Training loss: 3.4876...  0.8503 sec/batch\n",
      "checkpoints/i52_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 53...  Training loss: 3.4832...  0.8595 sec/batch\n",
      "checkpoints/i53_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 54...  Training loss: 3.5118...  0.8536 sec/batch\n",
      "checkpoints/i54_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 55...  Training loss: 3.5111...  0.8542 sec/batch\n",
      "checkpoints/i55_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 56...  Training loss: 3.5177...  0.8527 sec/batch\n",
      "checkpoints/i56_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 57...  Training loss: 3.5663...  0.8579 sec/batch\n",
      "checkpoints/i57_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 58...  Training loss: 3.5858...  0.8621 sec/batch\n",
      "checkpoints/i58_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 59...  Training loss: 3.5467...  0.8806 sec/batch\n",
      "checkpoints/i59_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 60...  Training loss: 3.5548...  0.8634 sec/batch\n",
      "checkpoints/i60_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 61...  Training loss: 3.5290...  0.8519 sec/batch\n",
      "checkpoints/i61_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 62...  Training loss: 3.5219...  0.8525 sec/batch\n",
      "checkpoints/i62_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 63...  Training loss: 3.5468...  0.8553 sec/batch\n",
      "checkpoints/i63_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 64...  Training loss: 3.5363...  0.8567 sec/batch\n",
      "checkpoints/i64_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 65...  Training loss: 3.5304...  0.8521 sec/batch\n",
      "checkpoints/i65_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 66...  Training loss: 3.5612...  0.8532 sec/batch\n",
      "checkpoints/i66_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 67...  Training loss: 3.5477...  0.8539 sec/batch\n",
      "checkpoints/i67_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 68...  Training loss: 3.5130...  0.8614 sec/batch\n",
      "checkpoints/i68_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 69...  Training loss: 3.4888...  0.8584 sec/batch\n",
      "checkpoints/i69_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 70...  Training loss: 3.4758...  0.8570 sec/batch\n",
      "checkpoints/i70_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 71...  Training loss: 3.4647...  0.8600 sec/batch\n",
      "checkpoints/i71_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 72...  Training loss: 3.4619...  0.8532 sec/batch\n",
      "checkpoints/i72_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 73...  Training loss: 3.4644...  0.8516 sec/batch\n",
      "checkpoints/i73_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 74...  Training loss: 3.4654...  0.8564 sec/batch\n",
      "checkpoints/i74_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 75...  Training loss: 3.4889...  0.8571 sec/batch\n",
      "checkpoints/i75_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 76...  Training loss: 3.4548...  0.8557 sec/batch\n",
      "checkpoints/i76_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 77...  Training loss: 3.4754...  0.8594 sec/batch\n",
      "checkpoints/i77_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 78...  Training loss: 3.4701...  0.8731 sec/batch\n",
      "checkpoints/i78_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 79...  Training loss: 3.4396...  0.8581 sec/batch\n",
      "checkpoints/i79_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 80...  Training loss: 3.4797...  0.8400 sec/batch\n",
      "checkpoints/i80_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 81...  Training loss: 3.4835...  0.8529 sec/batch\n",
      "checkpoints/i81_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 82...  Training loss: 3.4595...  0.8557 sec/batch\n",
      "checkpoints/i82_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 83...  Training loss: 3.4594...  0.8627 sec/batch\n",
      "checkpoints/i83_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 84...  Training loss: 3.4448...  0.8532 sec/batch\n",
      "checkpoints/i84_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 85...  Training loss: 3.4374...  0.8695 sec/batch\n",
      "checkpoints/i85_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 86...  Training loss: 3.4567...  0.8729 sec/batch\n",
      "checkpoints/i86_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 87...  Training loss: 3.4712...  0.8481 sec/batch\n",
      "checkpoints/i87_l512.ckpt\n",
      "Epoch: 1/10...  Training Step: 88...  Training loss: 3.4741...  0.8511 sec/batch\n",
      "checkpoints/i88_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [01:17<11:34, 77.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10...  Training Step: 89...  Training loss: 3.4734...  0.8615 sec/batch\n",
      "checkpoints/i89_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 90...  Training loss: 3.5432...  0.8509 sec/batch\n",
      "checkpoints/i90_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 91...  Training loss: 3.4682...  0.8782 sec/batch\n",
      "checkpoints/i91_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 92...  Training loss: 3.4383...  0.8913 sec/batch\n",
      "checkpoints/i92_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 93...  Training loss: 3.4562...  0.8585 sec/batch\n",
      "checkpoints/i93_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 94...  Training loss: 3.4665...  0.8527 sec/batch\n",
      "checkpoints/i94_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 95...  Training loss: 3.4526...  0.8588 sec/batch\n",
      "checkpoints/i95_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 96...  Training loss: 3.4667...  0.8496 sec/batch\n",
      "checkpoints/i96_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 97...  Training loss: 3.4411...  0.8651 sec/batch\n",
      "checkpoints/i97_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 98...  Training loss: 3.4360...  0.8629 sec/batch\n",
      "checkpoints/i98_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 99...  Training loss: 3.4417...  0.8661 sec/batch\n",
      "checkpoints/i99_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 100...  Training loss: 3.4147...  0.8930 sec/batch\n",
      "checkpoints/i100_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 101...  Training loss: 3.4146...  0.8535 sec/batch\n",
      "checkpoints/i101_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 102...  Training loss: 3.4430...  0.8502 sec/batch\n",
      "checkpoints/i102_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 103...  Training loss: 3.4077...  0.8593 sec/batch\n",
      "checkpoints/i103_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 104...  Training loss: 3.4505...  0.8597 sec/batch\n",
      "checkpoints/i104_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 105...  Training loss: 3.4464...  0.8706 sec/batch\n",
      "checkpoints/i105_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 106...  Training loss: 3.4180...  0.8832 sec/batch\n",
      "checkpoints/i106_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 107...  Training loss: 3.4282...  0.8543 sec/batch\n",
      "checkpoints/i107_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 108...  Training loss: 3.4364...  0.8588 sec/batch\n",
      "checkpoints/i108_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 109...  Training loss: 3.3985...  0.8658 sec/batch\n",
      "checkpoints/i109_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 110...  Training loss: 3.3887...  0.8665 sec/batch\n",
      "checkpoints/i110_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 111...  Training loss: 3.3920...  0.8567 sec/batch\n",
      "checkpoints/i111_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 112...  Training loss: 3.3574...  0.8930 sec/batch\n",
      "checkpoints/i112_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 113...  Training loss: 3.4084...  0.8774 sec/batch\n",
      "checkpoints/i113_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 114...  Training loss: 3.3787...  0.8582 sec/batch\n",
      "checkpoints/i114_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 115...  Training loss: 3.5472...  0.8703 sec/batch\n",
      "checkpoints/i115_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 116...  Training loss: 3.9985...  0.8580 sec/batch\n",
      "checkpoints/i116_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 117...  Training loss: 3.4922...  0.8555 sec/batch\n",
      "checkpoints/i117_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 118...  Training loss: 3.4370...  0.8569 sec/batch\n",
      "checkpoints/i118_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 119...  Training loss: 3.4313...  0.8920 sec/batch\n",
      "checkpoints/i119_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 120...  Training loss: 3.3979...  0.8665 sec/batch\n",
      "checkpoints/i120_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 121...  Training loss: 3.4079...  0.8641 sec/batch\n",
      "checkpoints/i121_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 122...  Training loss: 3.4163...  0.8524 sec/batch\n",
      "checkpoints/i122_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 123...  Training loss: 3.4130...  0.8593 sec/batch\n",
      "checkpoints/i123_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 124...  Training loss: 3.3793...  0.8597 sec/batch\n",
      "checkpoints/i124_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 125...  Training loss: 3.3948...  0.9060 sec/batch\n",
      "checkpoints/i125_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 126...  Training loss: 3.3756...  0.8721 sec/batch\n",
      "checkpoints/i126_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 127...  Training loss: 3.3629...  0.8603 sec/batch\n",
      "checkpoints/i127_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 128...  Training loss: 3.3936...  0.8591 sec/batch\n",
      "checkpoints/i128_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 129...  Training loss: 3.3719...  0.8579 sec/batch\n",
      "checkpoints/i129_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 130...  Training loss: 3.3556...  0.8567 sec/batch\n",
      "checkpoints/i130_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 131...  Training loss: 3.3995...  0.8752 sec/batch\n",
      "checkpoints/i131_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 132...  Training loss: 3.4033...  0.8678 sec/batch\n",
      "checkpoints/i132_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 133...  Training loss: 3.3947...  0.8533 sec/batch\n",
      "checkpoints/i133_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 134...  Training loss: 3.4449...  0.8546 sec/batch\n",
      "checkpoints/i134_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 135...  Training loss: 3.4695...  0.8564 sec/batch\n",
      "checkpoints/i135_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 136...  Training loss: 3.4434...  0.8538 sec/batch\n",
      "checkpoints/i136_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 137...  Training loss: 3.4537...  0.8634 sec/batch\n",
      "checkpoints/i137_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 138...  Training loss: 3.4236...  0.8851 sec/batch\n",
      "checkpoints/i138_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 139...  Training loss: 3.4333...  0.8571 sec/batch\n",
      "checkpoints/i139_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 140...  Training loss: 3.3197...  0.8617 sec/batch\n",
      "checkpoints/i140_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 141...  Training loss: 3.3497...  0.8534 sec/batch\n",
      "checkpoints/i141_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 142...  Training loss: 3.3156...  0.8651 sec/batch\n",
      "checkpoints/i142_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 143...  Training loss: 3.3640...  0.8576 sec/batch\n",
      "checkpoints/i143_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 144...  Training loss: 3.3462...  0.8581 sec/batch\n",
      "checkpoints/i144_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 145...  Training loss: 3.3462...  0.8787 sec/batch\n",
      "checkpoints/i145_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 146...  Training loss: 3.4065...  0.8625 sec/batch\n",
      "checkpoints/i146_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 147...  Training loss: 3.4042...  0.8622 sec/batch\n",
      "checkpoints/i147_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 148...  Training loss: 3.3575...  0.8579 sec/batch\n",
      "checkpoints/i148_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 149...  Training loss: 3.3851...  0.8661 sec/batch\n",
      "checkpoints/i149_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 150...  Training loss: 3.3572...  0.8620 sec/batch\n",
      "checkpoints/i150_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 151...  Training loss: 3.3354...  0.8832 sec/batch\n",
      "checkpoints/i151_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 152...  Training loss: 3.3571...  0.8888 sec/batch\n",
      "checkpoints/i152_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 153...  Training loss: 3.3388...  0.8492 sec/batch\n",
      "checkpoints/i153_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 154...  Training loss: 3.3299...  0.8659 sec/batch\n",
      "checkpoints/i154_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 155...  Training loss: 3.3479...  0.8546 sec/batch\n",
      "checkpoints/i155_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 156...  Training loss: 3.3397...  0.8676 sec/batch\n",
      "checkpoints/i156_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 157...  Training loss: 3.2949...  0.8741 sec/batch\n",
      "checkpoints/i157_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 158...  Training loss: 3.2723...  0.8747 sec/batch\n",
      "checkpoints/i158_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 159...  Training loss: 3.2480...  0.8549 sec/batch\n",
      "checkpoints/i159_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 160...  Training loss: 3.2496...  0.8636 sec/batch\n",
      "checkpoints/i160_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 161...  Training loss: 3.2317...  0.8552 sec/batch\n",
      "checkpoints/i161_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 162...  Training loss: 3.2171...  0.8546 sec/batch\n",
      "checkpoints/i162_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 163...  Training loss: 3.2161...  0.8684 sec/batch\n",
      "checkpoints/i163_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 164...  Training loss: 3.2314...  0.8561 sec/batch\n",
      "checkpoints/i164_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 165...  Training loss: 3.2017...  0.8525 sec/batch\n",
      "checkpoints/i165_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 166...  Training loss: 3.2093...  0.8765 sec/batch\n",
      "checkpoints/i166_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 167...  Training loss: 3.2002...  0.8736 sec/batch\n",
      "checkpoints/i167_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 168...  Training loss: 3.1742...  0.8634 sec/batch\n",
      "checkpoints/i168_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 169...  Training loss: 3.1985...  0.8596 sec/batch\n",
      "checkpoints/i169_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 170...  Training loss: 3.1934...  0.8549 sec/batch\n",
      "checkpoints/i170_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 171...  Training loss: 3.1792...  0.8552 sec/batch\n",
      "checkpoints/i171_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 172...  Training loss: 3.1674...  0.8590 sec/batch\n",
      "checkpoints/i172_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 173...  Training loss: 3.1381...  0.8649 sec/batch\n",
      "checkpoints/i173_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 174...  Training loss: 3.1560...  0.8755 sec/batch\n",
      "checkpoints/i174_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 175...  Training loss: 3.1318...  0.8936 sec/batch\n",
      "checkpoints/i175_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 176...  Training loss: 3.1510...  0.8550 sec/batch\n",
      "checkpoints/i176_l512.ckpt\n",
      "Epoch: 2/10...  Training Step: 177...  Training loss: 3.1553...  0.8611 sec/batch\n",
      "checkpoints/i177_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [02:34<10:16, 77.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10...  Training Step: 178...  Training loss: 3.1458...  0.8561 sec/batch\n",
      "checkpoints/i178_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 179...  Training loss: 3.2061...  0.8603 sec/batch\n",
      "checkpoints/i179_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 180...  Training loss: 3.1434...  0.8635 sec/batch\n",
      "checkpoints/i180_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 181...  Training loss: 3.1116...  0.8813 sec/batch\n",
      "checkpoints/i181_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 182...  Training loss: 3.1133...  0.8599 sec/batch\n",
      "checkpoints/i182_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 183...  Training loss: 3.1212...  0.8602 sec/batch\n",
      "checkpoints/i183_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 184...  Training loss: 3.1176...  0.8624 sec/batch\n",
      "checkpoints/i184_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 185...  Training loss: 3.1159...  0.8609 sec/batch\n",
      "checkpoints/i185_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 186...  Training loss: 3.0900...  0.8667 sec/batch\n",
      "checkpoints/i186_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 187...  Training loss: 3.0843...  0.8565 sec/batch\n",
      "checkpoints/i187_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 188...  Training loss: 3.0738...  0.8531 sec/batch\n",
      "checkpoints/i188_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 189...  Training loss: 3.0520...  0.8624 sec/batch\n",
      "checkpoints/i189_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 190...  Training loss: 3.0370...  0.8533 sec/batch\n",
      "checkpoints/i190_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 191...  Training loss: 3.0713...  0.8519 sec/batch\n",
      "checkpoints/i191_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 192...  Training loss: 3.0258...  0.8588 sec/batch\n",
      "checkpoints/i192_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 193...  Training loss: 3.0749...  0.8557 sec/batch\n",
      "checkpoints/i193_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 194...  Training loss: 3.0622...  0.8528 sec/batch\n",
      "checkpoints/i194_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 195...  Training loss: 3.0427...  0.8475 sec/batch\n",
      "checkpoints/i195_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 196...  Training loss: 3.0381...  0.8474 sec/batch\n",
      "checkpoints/i196_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 197...  Training loss: 3.0594...  0.8635 sec/batch\n",
      "checkpoints/i197_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 198...  Training loss: 3.0225...  0.8558 sec/batch\n",
      "checkpoints/i198_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 199...  Training loss: 3.0262...  0.8579 sec/batch\n",
      "checkpoints/i199_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 200...  Training loss: 3.0016...  0.8481 sec/batch\n",
      "checkpoints/i200_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 201...  Training loss: 2.9753...  0.9191 sec/batch\n",
      "checkpoints/i201_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 202...  Training loss: 3.0082...  0.8554 sec/batch\n",
      "checkpoints/i202_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 203...  Training loss: 2.9972...  0.8517 sec/batch\n",
      "checkpoints/i203_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 204...  Training loss: 2.9845...  0.8630 sec/batch\n",
      "checkpoints/i204_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 205...  Training loss: 3.0163...  0.8468 sec/batch\n",
      "checkpoints/i205_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 206...  Training loss: 2.9812...  0.8534 sec/batch\n",
      "checkpoints/i206_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 207...  Training loss: 2.9720...  0.8535 sec/batch\n",
      "checkpoints/i207_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 208...  Training loss: 2.9813...  0.8541 sec/batch\n",
      "checkpoints/i208_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 209...  Training loss: 2.9586...  0.8882 sec/batch\n",
      "checkpoints/i209_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 210...  Training loss: 2.9598...  0.8705 sec/batch\n",
      "checkpoints/i210_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 211...  Training loss: 2.9621...  0.8513 sec/batch\n",
      "checkpoints/i211_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 212...  Training loss: 2.9545...  0.8598 sec/batch\n",
      "checkpoints/i212_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 213...  Training loss: 2.9485...  0.8629 sec/batch\n",
      "checkpoints/i213_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 214...  Training loss: 2.9384...  0.8492 sec/batch\n",
      "checkpoints/i214_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 215...  Training loss: 2.9389...  0.8564 sec/batch\n",
      "checkpoints/i215_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 216...  Training loss: 2.9339...  0.8593 sec/batch\n",
      "checkpoints/i216_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 217...  Training loss: 2.9602...  0.8646 sec/batch\n",
      "checkpoints/i217_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 218...  Training loss: 2.9414...  0.8866 sec/batch\n",
      "checkpoints/i218_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 219...  Training loss: 2.9231...  0.8587 sec/batch\n",
      "checkpoints/i219_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 220...  Training loss: 2.9649...  0.8570 sec/batch\n",
      "checkpoints/i220_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 221...  Training loss: 2.9411...  0.8550 sec/batch\n",
      "checkpoints/i221_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 222...  Training loss: 2.9515...  0.8857 sec/batch\n",
      "checkpoints/i222_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 223...  Training loss: 2.9906...  0.8517 sec/batch\n",
      "checkpoints/i223_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 224...  Training loss: 3.0189...  0.8584 sec/batch\n",
      "checkpoints/i224_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 225...  Training loss: 2.9992...  0.8514 sec/batch\n",
      "checkpoints/i225_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 226...  Training loss: 2.9785...  0.8924 sec/batch\n",
      "checkpoints/i226_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 227...  Training loss: 2.9440...  0.8778 sec/batch\n",
      "checkpoints/i227_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 228...  Training loss: 2.9153...  0.8447 sec/batch\n",
      "checkpoints/i228_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 229...  Training loss: 2.9055...  0.8579 sec/batch\n",
      "checkpoints/i229_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 230...  Training loss: 2.8846...  0.8672 sec/batch\n",
      "checkpoints/i230_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 231...  Training loss: 2.9102...  0.8591 sec/batch\n",
      "checkpoints/i231_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 232...  Training loss: 2.9146...  0.8517 sec/batch\n",
      "checkpoints/i232_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 233...  Training loss: 2.8975...  0.8693 sec/batch\n",
      "checkpoints/i233_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 234...  Training loss: 2.9176...  0.8827 sec/batch\n",
      "checkpoints/i234_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 235...  Training loss: 2.9293...  0.8555 sec/batch\n",
      "checkpoints/i235_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 236...  Training loss: 2.9200...  0.8519 sec/batch\n",
      "checkpoints/i236_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 237...  Training loss: 2.8987...  0.8585 sec/batch\n",
      "checkpoints/i237_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 238...  Training loss: 2.9282...  0.8556 sec/batch\n",
      "checkpoints/i238_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 239...  Training loss: 2.8759...  0.8689 sec/batch\n",
      "checkpoints/i239_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 240...  Training loss: 2.8919...  0.8688 sec/batch\n",
      "checkpoints/i240_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 241...  Training loss: 2.9257...  0.8802 sec/batch\n",
      "checkpoints/i241_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 242...  Training loss: 2.9078...  0.8597 sec/batch\n",
      "checkpoints/i242_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 243...  Training loss: 2.9080...  0.8609 sec/batch\n",
      "checkpoints/i243_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 244...  Training loss: 2.9246...  0.8621 sec/batch\n",
      "checkpoints/i244_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 245...  Training loss: 2.9283...  0.8778 sec/batch\n",
      "checkpoints/i245_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 246...  Training loss: 2.8912...  0.8579 sec/batch\n",
      "checkpoints/i246_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 247...  Training loss: 2.8740...  0.8579 sec/batch\n",
      "checkpoints/i247_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 248...  Training loss: 2.8734...  0.8648 sec/batch\n",
      "checkpoints/i248_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 249...  Training loss: 2.8617...  0.8575 sec/batch\n",
      "checkpoints/i249_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 250...  Training loss: 2.8769...  0.8687 sec/batch\n",
      "checkpoints/i250_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 251...  Training loss: 2.8354...  0.8563 sec/batch\n",
      "checkpoints/i251_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 252...  Training loss: 2.8644...  0.8612 sec/batch\n",
      "checkpoints/i252_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 253...  Training loss: 2.8570...  0.8962 sec/batch\n",
      "checkpoints/i253_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 254...  Training loss: 2.8491...  0.8760 sec/batch\n",
      "checkpoints/i254_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 255...  Training loss: 2.8441...  0.8532 sec/batch\n",
      "checkpoints/i255_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 256...  Training loss: 2.8438...  0.8513 sec/batch\n",
      "checkpoints/i256_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 257...  Training loss: 2.8303...  0.8610 sec/batch\n",
      "checkpoints/i257_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 258...  Training loss: 2.8590...  0.8523 sec/batch\n",
      "checkpoints/i258_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 259...  Training loss: 2.8469...  0.8607 sec/batch\n",
      "checkpoints/i259_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 260...  Training loss: 2.8466...  0.8926 sec/batch\n",
      "checkpoints/i260_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 261...  Training loss: 2.8445...  0.8619 sec/batch\n",
      "checkpoints/i261_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 262...  Training loss: 2.8106...  0.8631 sec/batch\n",
      "checkpoints/i262_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 263...  Training loss: 2.8304...  0.8614 sec/batch\n",
      "checkpoints/i263_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 264...  Training loss: 2.8146...  0.8590 sec/batch\n",
      "checkpoints/i264_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 265...  Training loss: 2.8410...  0.8595 sec/batch\n",
      "checkpoints/i265_l512.ckpt\n",
      "Epoch: 3/10...  Training Step: 266...  Training loss: 2.8323...  0.8815 sec/batch\n",
      "checkpoints/i266_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [03:51<08:59, 77.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10...  Training Step: 267...  Training loss: 2.8492...  0.8784 sec/batch\n",
      "checkpoints/i267_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 268...  Training loss: 2.9118...  0.8689 sec/batch\n",
      "checkpoints/i268_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 269...  Training loss: 2.8350...  0.8600 sec/batch\n",
      "checkpoints/i269_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 270...  Training loss: 2.8252...  0.8535 sec/batch\n",
      "checkpoints/i270_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 271...  Training loss: 2.8306...  0.8582 sec/batch\n",
      "checkpoints/i271_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 272...  Training loss: 2.8345...  0.8624 sec/batch\n",
      "checkpoints/i272_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 273...  Training loss: 2.8422...  0.8841 sec/batch\n",
      "checkpoints/i273_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 274...  Training loss: 2.8353...  0.8574 sec/batch\n",
      "checkpoints/i274_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 275...  Training loss: 2.8257...  0.8575 sec/batch\n",
      "checkpoints/i275_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 276...  Training loss: 2.8333...  0.8547 sec/batch\n",
      "checkpoints/i276_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 277...  Training loss: 2.8103...  0.8627 sec/batch\n",
      "checkpoints/i277_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 278...  Training loss: 2.7942...  0.8630 sec/batch\n",
      "checkpoints/i278_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 279...  Training loss: 2.7973...  0.8852 sec/batch\n",
      "checkpoints/i279_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 280...  Training loss: 2.8275...  0.8746 sec/batch\n",
      "checkpoints/i280_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 281...  Training loss: 2.8016...  0.8635 sec/batch\n",
      "checkpoints/i281_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 282...  Training loss: 2.8317...  0.8628 sec/batch\n",
      "checkpoints/i282_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 283...  Training loss: 2.8346...  0.8653 sec/batch\n",
      "checkpoints/i283_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 284...  Training loss: 2.7919...  0.8606 sec/batch\n",
      "checkpoints/i284_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 285...  Training loss: 2.8221...  0.8484 sec/batch\n",
      "checkpoints/i285_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 286...  Training loss: 2.8324...  0.8964 sec/batch\n",
      "checkpoints/i286_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 287...  Training loss: 2.7946...  0.8766 sec/batch\n",
      "checkpoints/i287_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 288...  Training loss: 2.7851...  0.8607 sec/batch\n",
      "checkpoints/i288_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 289...  Training loss: 2.8091...  0.8479 sec/batch\n",
      "checkpoints/i289_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 290...  Training loss: 2.7496...  0.8556 sec/batch\n",
      "checkpoints/i290_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 291...  Training loss: 2.8041...  0.8737 sec/batch\n",
      "checkpoints/i291_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 292...  Training loss: 2.7872...  0.8523 sec/batch\n",
      "checkpoints/i292_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 293...  Training loss: 2.7867...  0.8768 sec/batch\n",
      "checkpoints/i293_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 294...  Training loss: 2.8032...  0.8879 sec/batch\n",
      "checkpoints/i294_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 295...  Training loss: 2.7914...  0.8596 sec/batch\n",
      "checkpoints/i295_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 296...  Training loss: 2.7905...  0.8628 sec/batch\n",
      "checkpoints/i296_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 297...  Training loss: 2.7952...  0.8595 sec/batch\n",
      "checkpoints/i297_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 298...  Training loss: 2.7524...  0.8540 sec/batch\n",
      "checkpoints/i298_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 299...  Training loss: 2.7806...  0.8475 sec/batch\n",
      "checkpoints/i299_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 300...  Training loss: 2.7858...  0.8835 sec/batch\n",
      "checkpoints/i300_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 301...  Training loss: 2.7740...  0.8596 sec/batch\n",
      "checkpoints/i301_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 302...  Training loss: 2.7700...  0.8879 sec/batch\n",
      "checkpoints/i302_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 303...  Training loss: 2.7725...  0.8463 sec/batch\n",
      "checkpoints/i303_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 304...  Training loss: 2.7758...  0.8552 sec/batch\n",
      "checkpoints/i304_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 305...  Training loss: 2.7567...  0.8592 sec/batch\n",
      "checkpoints/i305_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 306...  Training loss: 2.8026...  0.8536 sec/batch\n",
      "checkpoints/i306_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 307...  Training loss: 2.7805...  0.8608 sec/batch\n",
      "checkpoints/i307_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 308...  Training loss: 2.7775...  0.8897 sec/batch\n",
      "checkpoints/i308_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 309...  Training loss: 2.7895...  0.8644 sec/batch\n",
      "checkpoints/i309_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 310...  Training loss: 2.7960...  0.8641 sec/batch\n",
      "checkpoints/i310_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 311...  Training loss: 2.7907...  0.8576 sec/batch\n",
      "checkpoints/i311_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 312...  Training loss: 2.8047...  0.8599 sec/batch\n",
      "checkpoints/i312_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 313...  Training loss: 2.8229...  0.8564 sec/batch\n",
      "checkpoints/i313_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 314...  Training loss: 2.8185...  0.8544 sec/batch\n",
      "checkpoints/i314_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 315...  Training loss: 2.8073...  0.8928 sec/batch\n",
      "checkpoints/i315_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 316...  Training loss: 2.7822...  0.8761 sec/batch\n",
      "checkpoints/i316_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 317...  Training loss: 2.7597...  0.8593 sec/batch\n",
      "checkpoints/i317_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 318...  Training loss: 2.7558...  0.8628 sec/batch\n",
      "checkpoints/i318_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 319...  Training loss: 2.7436...  0.8634 sec/batch\n",
      "checkpoints/i319_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 320...  Training loss: 2.7663...  0.8644 sec/batch\n",
      "checkpoints/i320_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 321...  Training loss: 2.7722...  0.8629 sec/batch\n",
      "checkpoints/i321_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 322...  Training loss: 2.7526...  0.8736 sec/batch\n",
      "checkpoints/i322_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 323...  Training loss: 2.7732...  0.8680 sec/batch\n",
      "checkpoints/i323_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 324...  Training loss: 2.7860...  0.8716 sec/batch\n",
      "checkpoints/i324_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 325...  Training loss: 2.7783...  0.8712 sec/batch\n",
      "checkpoints/i325_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 326...  Training loss: 2.7497...  0.8532 sec/batch\n",
      "checkpoints/i326_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 327...  Training loss: 2.7759...  0.8538 sec/batch\n",
      "checkpoints/i327_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 328...  Training loss: 2.7374...  0.8686 sec/batch\n",
      "checkpoints/i328_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 329...  Training loss: 2.7580...  0.8604 sec/batch\n",
      "checkpoints/i329_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 330...  Training loss: 2.7771...  0.8858 sec/batch\n",
      "checkpoints/i330_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 331...  Training loss: 2.7695...  0.8621 sec/batch\n",
      "checkpoints/i331_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 332...  Training loss: 2.7637...  0.8560 sec/batch\n",
      "checkpoints/i332_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 333...  Training loss: 2.7845...  0.8621 sec/batch\n",
      "checkpoints/i333_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 334...  Training loss: 2.7839...  0.8542 sec/batch\n",
      "checkpoints/i334_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 335...  Training loss: 2.7569...  0.8537 sec/batch\n",
      "checkpoints/i335_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 336...  Training loss: 2.7511...  0.8550 sec/batch\n",
      "checkpoints/i336_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 337...  Training loss: 2.7538...  0.8769 sec/batch\n",
      "checkpoints/i337_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 338...  Training loss: 2.7354...  0.8736 sec/batch\n",
      "checkpoints/i338_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 339...  Training loss: 2.7571...  0.8655 sec/batch\n",
      "checkpoints/i339_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 340...  Training loss: 2.7198...  0.8588 sec/batch\n",
      "checkpoints/i340_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 341...  Training loss: 2.7424...  0.8526 sec/batch\n",
      "checkpoints/i341_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 342...  Training loss: 2.7316...  0.8676 sec/batch\n",
      "checkpoints/i342_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 343...  Training loss: 2.7254...  0.8685 sec/batch\n",
      "checkpoints/i343_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 344...  Training loss: 2.7165...  0.8539 sec/batch\n",
      "checkpoints/i344_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 345...  Training loss: 2.7227...  0.8581 sec/batch\n",
      "checkpoints/i345_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 346...  Training loss: 2.7076...  0.8488 sec/batch\n",
      "checkpoints/i346_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 347...  Training loss: 2.7400...  0.8551 sec/batch\n",
      "checkpoints/i347_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 348...  Training loss: 2.7337...  0.8598 sec/batch\n",
      "checkpoints/i348_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 349...  Training loss: 2.7145...  0.8574 sec/batch\n",
      "checkpoints/i349_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 350...  Training loss: 2.7262...  0.8602 sec/batch\n",
      "checkpoints/i350_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 351...  Training loss: 2.6961...  0.8596 sec/batch\n",
      "checkpoints/i351_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 352...  Training loss: 2.7069...  0.8539 sec/batch\n",
      "checkpoints/i352_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 353...  Training loss: 2.6916...  0.8590 sec/batch\n",
      "checkpoints/i353_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 354...  Training loss: 2.7190...  0.8629 sec/batch\n",
      "checkpoints/i354_l512.ckpt\n",
      "Epoch: 4/10...  Training Step: 355...  Training loss: 2.7190...  0.8530 sec/batch\n",
      "checkpoints/i355_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [05:07<07:41, 76.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10...  Training Step: 356...  Training loss: 2.7259...  0.8587 sec/batch\n",
      "checkpoints/i356_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 357...  Training loss: 2.7966...  0.8587 sec/batch\n",
      "checkpoints/i357_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 358...  Training loss: 2.7185...  0.8544 sec/batch\n",
      "checkpoints/i358_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 359...  Training loss: 2.7208...  0.8901 sec/batch\n",
      "checkpoints/i359_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 360...  Training loss: 2.7216...  0.8699 sec/batch\n",
      "checkpoints/i360_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 361...  Training loss: 2.7238...  0.8543 sec/batch\n",
      "checkpoints/i361_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 362...  Training loss: 2.7290...  0.8670 sec/batch\n",
      "checkpoints/i362_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 363...  Training loss: 2.7301...  0.8539 sec/batch\n",
      "checkpoints/i363_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 364...  Training loss: 2.7123...  0.8990 sec/batch\n",
      "checkpoints/i364_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 365...  Training loss: 2.7229...  0.8703 sec/batch\n",
      "checkpoints/i365_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 366...  Training loss: 2.7058...  0.8597 sec/batch\n",
      "checkpoints/i366_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 367...  Training loss: 2.7026...  0.8570 sec/batch\n",
      "checkpoints/i367_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 368...  Training loss: 2.6973...  0.8554 sec/batch\n",
      "checkpoints/i368_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 369...  Training loss: 2.7119...  0.8557 sec/batch\n",
      "checkpoints/i369_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 370...  Training loss: 2.6893...  0.8490 sec/batch\n",
      "checkpoints/i370_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 371...  Training loss: 2.7384...  0.8696 sec/batch\n",
      "checkpoints/i371_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 372...  Training loss: 2.7327...  0.8781 sec/batch\n",
      "checkpoints/i372_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 373...  Training loss: 2.6787...  0.8571 sec/batch\n",
      "checkpoints/i373_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 374...  Training loss: 2.7143...  0.8622 sec/batch\n",
      "checkpoints/i374_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 375...  Training loss: 2.7208...  0.8671 sec/batch\n",
      "checkpoints/i375_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 376...  Training loss: 2.6926...  0.8524 sec/batch\n",
      "checkpoints/i376_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 377...  Training loss: 2.6814...  0.8656 sec/batch\n",
      "checkpoints/i377_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 378...  Training loss: 2.6925...  0.8887 sec/batch\n",
      "checkpoints/i378_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 379...  Training loss: 2.6564...  0.8554 sec/batch\n",
      "checkpoints/i379_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 380...  Training loss: 2.7097...  0.8669 sec/batch\n",
      "checkpoints/i380_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 381...  Training loss: 2.7015...  0.8505 sec/batch\n",
      "checkpoints/i381_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 382...  Training loss: 2.6974...  0.8476 sec/batch\n",
      "checkpoints/i382_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 383...  Training loss: 2.6961...  0.8816 sec/batch\n",
      "checkpoints/i383_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 384...  Training loss: 2.7031...  0.8805 sec/batch\n",
      "checkpoints/i384_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 385...  Training loss: 2.7063...  0.8669 sec/batch\n",
      "checkpoints/i385_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 386...  Training loss: 2.7100...  0.8635 sec/batch\n",
      "checkpoints/i386_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 387...  Training loss: 2.6651...  0.8647 sec/batch\n",
      "checkpoints/i387_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 388...  Training loss: 2.6824...  0.8576 sec/batch\n",
      "checkpoints/i388_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 389...  Training loss: 2.7056...  0.8819 sec/batch\n",
      "checkpoints/i389_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 390...  Training loss: 2.6731...  0.8909 sec/batch\n",
      "checkpoints/i390_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 391...  Training loss: 2.6796...  0.8659 sec/batch\n",
      "checkpoints/i391_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 392...  Training loss: 2.6735...  0.8575 sec/batch\n",
      "checkpoints/i392_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 393...  Training loss: 2.6895...  0.8659 sec/batch\n",
      "checkpoints/i393_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 394...  Training loss: 2.6693...  0.8583 sec/batch\n",
      "checkpoints/i394_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 395...  Training loss: 2.7076...  0.8769 sec/batch\n",
      "checkpoints/i395_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 396...  Training loss: 2.6889...  0.8829 sec/batch\n",
      "checkpoints/i396_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 397...  Training loss: 2.6876...  0.8662 sec/batch\n",
      "checkpoints/i397_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 398...  Training loss: 2.7034...  0.8546 sec/batch\n",
      "checkpoints/i398_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 399...  Training loss: 2.6888...  0.8570 sec/batch\n",
      "checkpoints/i399_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 400...  Training loss: 2.6923...  0.8594 sec/batch\n",
      "checkpoints/i400_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 401...  Training loss: 2.6902...  0.9097 sec/batch\n",
      "checkpoints/i401_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 402...  Training loss: 2.7096...  0.8880 sec/batch\n",
      "checkpoints/i402_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 403...  Training loss: 2.7128...  0.8906 sec/batch\n",
      "checkpoints/i403_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 404...  Training loss: 2.6952...  0.8570 sec/batch\n",
      "checkpoints/i404_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 405...  Training loss: 2.6903...  0.8482 sec/batch\n",
      "checkpoints/i405_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 406...  Training loss: 2.6725...  0.8593 sec/batch\n",
      "checkpoints/i406_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 407...  Training loss: 2.6606...  0.8528 sec/batch\n",
      "checkpoints/i407_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 408...  Training loss: 2.6613...  0.8727 sec/batch\n",
      "checkpoints/i408_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 409...  Training loss: 2.6819...  0.8762 sec/batch\n",
      "checkpoints/i409_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 410...  Training loss: 2.6750...  0.8819 sec/batch\n",
      "checkpoints/i410_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 411...  Training loss: 2.6614...  0.8878 sec/batch\n",
      "checkpoints/i411_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 412...  Training loss: 2.6892...  0.8576 sec/batch\n",
      "checkpoints/i412_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 413...  Training loss: 2.6948...  0.8577 sec/batch\n",
      "checkpoints/i413_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 414...  Training loss: 2.6674...  0.8599 sec/batch\n",
      "checkpoints/i414_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 415...  Training loss: 2.6703...  0.8637 sec/batch\n",
      "checkpoints/i415_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 416...  Training loss: 2.6881...  0.8864 sec/batch\n",
      "checkpoints/i416_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 417...  Training loss: 2.6414...  0.8621 sec/batch\n",
      "checkpoints/i417_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 418...  Training loss: 2.6575...  0.8589 sec/batch\n",
      "checkpoints/i418_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 419...  Training loss: 2.6909...  0.8619 sec/batch\n",
      "checkpoints/i419_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 420...  Training loss: 2.6668...  0.8539 sec/batch\n",
      "checkpoints/i420_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 421...  Training loss: 2.6656...  0.8534 sec/batch\n",
      "checkpoints/i421_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 422...  Training loss: 2.6862...  0.8535 sec/batch\n",
      "checkpoints/i422_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 423...  Training loss: 2.6859...  0.8855 sec/batch\n",
      "checkpoints/i423_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 424...  Training loss: 2.6748...  0.8582 sec/batch\n",
      "checkpoints/i424_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 425...  Training loss: 2.6620...  0.8521 sec/batch\n",
      "checkpoints/i425_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 426...  Training loss: 2.6794...  0.8557 sec/batch\n",
      "checkpoints/i426_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 427...  Training loss: 2.6465...  0.8549 sec/batch\n",
      "checkpoints/i427_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 428...  Training loss: 2.6689...  0.8540 sec/batch\n",
      "checkpoints/i428_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 429...  Training loss: 2.6361...  0.8623 sec/batch\n",
      "checkpoints/i429_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 430...  Training loss: 2.6616...  0.8594 sec/batch\n",
      "checkpoints/i430_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 431...  Training loss: 2.6479...  0.8520 sec/batch\n",
      "checkpoints/i431_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 432...  Training loss: 2.6474...  0.8565 sec/batch\n",
      "checkpoints/i432_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 433...  Training loss: 2.6345...  0.8475 sec/batch\n",
      "checkpoints/i433_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 434...  Training loss: 2.6420...  0.8597 sec/batch\n",
      "checkpoints/i434_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 435...  Training loss: 2.6210...  0.8614 sec/batch\n",
      "checkpoints/i435_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 436...  Training loss: 2.6595...  0.8532 sec/batch\n",
      "checkpoints/i436_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 437...  Training loss: 2.6537...  0.8509 sec/batch\n",
      "checkpoints/i437_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 438...  Training loss: 2.6422...  0.8557 sec/batch\n",
      "checkpoints/i438_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 439...  Training loss: 2.6379...  0.8530 sec/batch\n",
      "checkpoints/i439_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 440...  Training loss: 2.6215...  0.8571 sec/batch\n",
      "checkpoints/i440_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 441...  Training loss: 2.6233...  0.8612 sec/batch\n",
      "checkpoints/i441_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 442...  Training loss: 2.6169...  0.8502 sec/batch\n",
      "checkpoints/i442_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 443...  Training loss: 2.6384...  0.8591 sec/batch\n",
      "checkpoints/i443_l512.ckpt\n",
      "Epoch: 5/10...  Training Step: 444...  Training loss: 2.6321...  0.8575 sec/batch\n",
      "checkpoints/i444_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [06:24<06:24, 76.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10...  Training Step: 445...  Training loss: 2.6448...  0.8672 sec/batch\n",
      "checkpoints/i445_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 446...  Training loss: 2.7092...  0.8559 sec/batch\n",
      "checkpoints/i446_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 447...  Training loss: 2.6429...  0.8602 sec/batch\n",
      "checkpoints/i447_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 448...  Training loss: 2.6372...  0.8512 sec/batch\n",
      "checkpoints/i448_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 449...  Training loss: 2.6418...  0.8560 sec/batch\n",
      "checkpoints/i449_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 450...  Training loss: 2.6374...  0.8588 sec/batch\n",
      "checkpoints/i450_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 451...  Training loss: 2.6523...  0.8713 sec/batch\n",
      "checkpoints/i451_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 452...  Training loss: 2.6527...  0.8784 sec/batch\n",
      "checkpoints/i452_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 453...  Training loss: 2.6336...  0.8573 sec/batch\n",
      "checkpoints/i453_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 454...  Training loss: 2.6480...  0.8546 sec/batch\n",
      "checkpoints/i454_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 455...  Training loss: 2.6299...  0.8602 sec/batch\n",
      "checkpoints/i455_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 456...  Training loss: 2.6140...  0.8674 sec/batch\n",
      "checkpoints/i456_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 457...  Training loss: 2.6212...  0.8621 sec/batch\n",
      "checkpoints/i457_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 458...  Training loss: 2.6247...  0.8776 sec/batch\n",
      "checkpoints/i458_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 459...  Training loss: 2.6217...  0.8802 sec/batch\n",
      "checkpoints/i459_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 460...  Training loss: 2.6491...  0.8561 sec/batch\n",
      "checkpoints/i460_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 461...  Training loss: 2.6520...  0.8571 sec/batch\n",
      "checkpoints/i461_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 462...  Training loss: 2.6118...  0.8535 sec/batch\n",
      "checkpoints/i462_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 463...  Training loss: 2.6347...  0.8592 sec/batch\n",
      "checkpoints/i463_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 464...  Training loss: 2.6480...  0.8615 sec/batch\n",
      "checkpoints/i464_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 465...  Training loss: 2.6122...  0.8947 sec/batch\n",
      "checkpoints/i465_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 466...  Training loss: 2.6095...  0.8699 sec/batch\n",
      "checkpoints/i466_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 467...  Training loss: 2.6185...  0.8594 sec/batch\n",
      "checkpoints/i467_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 468...  Training loss: 2.5801...  0.8561 sec/batch\n",
      "checkpoints/i468_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 469...  Training loss: 2.6157...  0.8588 sec/batch\n",
      "checkpoints/i469_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 470...  Training loss: 2.6159...  0.8658 sec/batch\n",
      "checkpoints/i470_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 471...  Training loss: 2.6099...  0.8689 sec/batch\n",
      "checkpoints/i471_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 472...  Training loss: 2.6087...  0.8720 sec/batch\n",
      "checkpoints/i472_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 473...  Training loss: 2.6219...  0.8796 sec/batch\n",
      "checkpoints/i473_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 474...  Training loss: 2.6346...  0.8571 sec/batch\n",
      "checkpoints/i474_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 475...  Training loss: 2.6236...  0.8604 sec/batch\n",
      "checkpoints/i475_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 476...  Training loss: 2.5905...  0.8731 sec/batch\n",
      "checkpoints/i476_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 477...  Training loss: 2.5981...  0.8628 sec/batch\n",
      "checkpoints/i477_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 478...  Training loss: 2.6205...  0.8653 sec/batch\n",
      "checkpoints/i478_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 479...  Training loss: 2.5919...  0.8730 sec/batch\n",
      "checkpoints/i479_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 480...  Training loss: 2.6074...  0.8709 sec/batch\n",
      "checkpoints/i480_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 481...  Training loss: 2.5959...  0.8501 sec/batch\n",
      "checkpoints/i481_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 482...  Training loss: 2.6120...  0.8725 sec/batch\n",
      "checkpoints/i482_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 483...  Training loss: 2.5924...  0.8500 sec/batch\n",
      "checkpoints/i483_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 484...  Training loss: 2.6293...  0.8577 sec/batch\n",
      "checkpoints/i484_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 485...  Training loss: 2.6088...  0.8902 sec/batch\n",
      "checkpoints/i485_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 486...  Training loss: 2.6163...  0.8418 sec/batch\n",
      "checkpoints/i486_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 487...  Training loss: 2.6268...  0.8531 sec/batch\n",
      "checkpoints/i487_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 488...  Training loss: 2.6146...  0.8644 sec/batch\n",
      "checkpoints/i488_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 489...  Training loss: 2.6139...  0.8621 sec/batch\n",
      "checkpoints/i489_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 490...  Training loss: 2.6250...  0.8579 sec/batch\n",
      "checkpoints/i490_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 491...  Training loss: 2.6317...  0.8617 sec/batch\n",
      "checkpoints/i491_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 492...  Training loss: 2.6423...  0.8809 sec/batch\n",
      "checkpoints/i492_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 493...  Training loss: 2.6179...  0.8735 sec/batch\n",
      "checkpoints/i493_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 494...  Training loss: 2.6175...  0.8647 sec/batch\n",
      "checkpoints/i494_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 495...  Training loss: 2.6138...  0.8642 sec/batch\n",
      "checkpoints/i495_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 496...  Training loss: 2.5903...  0.8544 sec/batch\n",
      "checkpoints/i496_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 497...  Training loss: 2.5902...  0.8596 sec/batch\n",
      "checkpoints/i497_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 498...  Training loss: 2.6194...  0.8756 sec/batch\n",
      "checkpoints/i498_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 499...  Training loss: 2.6164...  0.8725 sec/batch\n",
      "checkpoints/i499_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 500...  Training loss: 2.5968...  0.8565 sec/batch\n",
      "checkpoints/i500_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 501...  Training loss: 2.6214...  0.8575 sec/batch\n",
      "checkpoints/i501_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 502...  Training loss: 2.6095...  0.8596 sec/batch\n",
      "checkpoints/i502_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 503...  Training loss: 2.5958...  0.8566 sec/batch\n",
      "checkpoints/i503_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 504...  Training loss: 2.5982...  0.8576 sec/batch\n",
      "checkpoints/i504_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 505...  Training loss: 2.6071...  0.8516 sec/batch\n",
      "checkpoints/i505_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 506...  Training loss: 2.5709...  0.8788 sec/batch\n",
      "checkpoints/i506_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 507...  Training loss: 2.5880...  0.8788 sec/batch\n",
      "checkpoints/i507_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 508...  Training loss: 2.6140...  0.8543 sec/batch\n",
      "checkpoints/i508_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 509...  Training loss: 2.5894...  0.8591 sec/batch\n",
      "checkpoints/i509_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 510...  Training loss: 2.6029...  0.8699 sec/batch\n",
      "checkpoints/i510_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 511...  Training loss: 2.6335...  0.8508 sec/batch\n",
      "checkpoints/i511_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 512...  Training loss: 2.6269...  0.8590 sec/batch\n",
      "checkpoints/i512_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 513...  Training loss: 2.6055...  0.8975 sec/batch\n",
      "checkpoints/i513_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 514...  Training loss: 2.6025...  0.8604 sec/batch\n",
      "checkpoints/i514_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 515...  Training loss: 2.6142...  0.8442 sec/batch\n",
      "checkpoints/i515_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 516...  Training loss: 2.5795...  0.8661 sec/batch\n",
      "checkpoints/i516_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 517...  Training loss: 2.6083...  0.8857 sec/batch\n",
      "checkpoints/i517_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 518...  Training loss: 2.5639...  0.8581 sec/batch\n",
      "checkpoints/i518_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 519...  Training loss: 2.5892...  0.8545 sec/batch\n",
      "checkpoints/i519_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 520...  Training loss: 2.5792...  0.8465 sec/batch\n",
      "checkpoints/i520_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 521...  Training loss: 2.5828...  0.8614 sec/batch\n",
      "checkpoints/i521_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 522...  Training loss: 2.5719...  0.8912 sec/batch\n",
      "checkpoints/i522_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 523...  Training loss: 2.5852...  0.8655 sec/batch\n",
      "checkpoints/i523_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 524...  Training loss: 2.5654...  0.8620 sec/batch\n",
      "checkpoints/i524_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 525...  Training loss: 2.6018...  0.8635 sec/batch\n",
      "checkpoints/i525_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 526...  Training loss: 2.5866...  0.8550 sec/batch\n",
      "checkpoints/i526_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 527...  Training loss: 2.5857...  0.8652 sec/batch\n",
      "checkpoints/i527_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 528...  Training loss: 2.5857...  0.8623 sec/batch\n",
      "checkpoints/i528_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 529...  Training loss: 2.5606...  0.8832 sec/batch\n",
      "checkpoints/i529_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 530...  Training loss: 2.5687...  0.8544 sec/batch\n",
      "checkpoints/i530_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 531...  Training loss: 2.5398...  0.8630 sec/batch\n",
      "checkpoints/i531_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 532...  Training loss: 2.5879...  0.8533 sec/batch\n",
      "checkpoints/i532_l512.ckpt\n",
      "Epoch: 6/10...  Training Step: 533...  Training loss: 2.5665...  0.8627 sec/batch\n",
      "checkpoints/i533_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [07:41<05:07, 76.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10...  Training Step: 534...  Training loss: 2.5812...  0.8535 sec/batch\n",
      "checkpoints/i534_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 535...  Training loss: 2.6364...  0.8533 sec/batch\n",
      "checkpoints/i535_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 536...  Training loss: 2.5866...  0.8507 sec/batch\n",
      "checkpoints/i536_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 537...  Training loss: 2.5792...  0.8548 sec/batch\n",
      "checkpoints/i537_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 538...  Training loss: 2.5840...  0.8580 sec/batch\n",
      "checkpoints/i538_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 539...  Training loss: 2.5819...  0.8487 sec/batch\n",
      "checkpoints/i539_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 540...  Training loss: 2.5813...  0.8533 sec/batch\n",
      "checkpoints/i540_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 541...  Training loss: 2.5931...  0.8564 sec/batch\n",
      "checkpoints/i541_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 542...  Training loss: 2.5751...  0.8605 sec/batch\n",
      "checkpoints/i542_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 543...  Training loss: 2.5877...  0.8615 sec/batch\n",
      "checkpoints/i543_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 544...  Training loss: 2.5523...  0.8645 sec/batch\n",
      "checkpoints/i544_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 545...  Training loss: 2.5500...  0.8527 sec/batch\n",
      "checkpoints/i545_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 546...  Training loss: 2.5540...  0.8585 sec/batch\n",
      "checkpoints/i546_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 547...  Training loss: 2.5566...  0.8581 sec/batch\n",
      "checkpoints/i547_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 548...  Training loss: 2.5514...  0.8531 sec/batch\n",
      "checkpoints/i548_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 549...  Training loss: 2.5848...  0.8658 sec/batch\n",
      "checkpoints/i549_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 550...  Training loss: 2.5810...  0.8470 sec/batch\n",
      "checkpoints/i550_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 551...  Training loss: 2.5430...  0.8600 sec/batch\n",
      "checkpoints/i551_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 552...  Training loss: 2.5727...  0.8505 sec/batch\n",
      "checkpoints/i552_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 553...  Training loss: 2.5751...  0.8597 sec/batch\n",
      "checkpoints/i553_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 554...  Training loss: 2.5578...  0.8596 sec/batch\n",
      "checkpoints/i554_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 555...  Training loss: 2.5521...  0.8705 sec/batch\n",
      "checkpoints/i555_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 556...  Training loss: 2.5704...  0.8960 sec/batch\n",
      "checkpoints/i556_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 557...  Training loss: 2.5316...  0.8621 sec/batch\n",
      "checkpoints/i557_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 558...  Training loss: 2.5454...  0.8569 sec/batch\n",
      "checkpoints/i558_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 559...  Training loss: 2.5496...  0.8539 sec/batch\n",
      "checkpoints/i559_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 560...  Training loss: 2.5580...  0.8572 sec/batch\n",
      "checkpoints/i560_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 561...  Training loss: 2.5512...  0.8535 sec/batch\n",
      "checkpoints/i561_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 562...  Training loss: 2.5603...  0.8634 sec/batch\n",
      "checkpoints/i562_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 563...  Training loss: 2.5759...  0.8710 sec/batch\n",
      "checkpoints/i563_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 564...  Training loss: 2.5667...  0.8768 sec/batch\n",
      "checkpoints/i564_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 565...  Training loss: 2.5296...  0.8647 sec/batch\n",
      "checkpoints/i565_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 566...  Training loss: 2.5410...  0.8585 sec/batch\n",
      "checkpoints/i566_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 567...  Training loss: 2.5471...  0.8617 sec/batch\n",
      "checkpoints/i567_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 568...  Training loss: 2.5268...  0.8631 sec/batch\n",
      "checkpoints/i568_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 569...  Training loss: 2.5418...  0.8619 sec/batch\n",
      "checkpoints/i569_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 570...  Training loss: 2.5256...  0.8560 sec/batch\n",
      "checkpoints/i570_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 571...  Training loss: 2.5565...  0.8820 sec/batch\n",
      "checkpoints/i571_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 572...  Training loss: 2.5280...  0.8736 sec/batch\n",
      "checkpoints/i572_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 573...  Training loss: 2.5685...  0.8606 sec/batch\n",
      "checkpoints/i573_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 574...  Training loss: 2.5485...  0.8635 sec/batch\n",
      "checkpoints/i574_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 575...  Training loss: 2.5453...  0.8556 sec/batch\n",
      "checkpoints/i575_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 576...  Training loss: 2.5658...  0.8539 sec/batch\n",
      "checkpoints/i576_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 577...  Training loss: 2.5485...  0.8599 sec/batch\n",
      "checkpoints/i577_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 578...  Training loss: 2.5590...  0.8578 sec/batch\n",
      "checkpoints/i578_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 579...  Training loss: 2.5518...  0.8746 sec/batch\n",
      "checkpoints/i579_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 580...  Training loss: 2.5842...  0.8741 sec/batch\n",
      "checkpoints/i580_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 581...  Training loss: 2.5933...  0.8679 sec/batch\n",
      "checkpoints/i581_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 582...  Training loss: 2.5543...  0.8648 sec/batch\n",
      "checkpoints/i582_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 583...  Training loss: 2.5761...  0.8555 sec/batch\n",
      "checkpoints/i583_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 584...  Training loss: 2.5691...  0.8716 sec/batch\n",
      "checkpoints/i584_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 585...  Training loss: 2.5442...  0.8759 sec/batch\n",
      "checkpoints/i585_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 586...  Training loss: 2.5395...  0.8555 sec/batch\n",
      "checkpoints/i586_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 587...  Training loss: 2.5615...  0.8534 sec/batch\n",
      "checkpoints/i587_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 588...  Training loss: 2.5663...  0.8529 sec/batch\n",
      "checkpoints/i588_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 589...  Training loss: 2.5402...  0.8539 sec/batch\n",
      "checkpoints/i589_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 590...  Training loss: 2.5682...  0.8593 sec/batch\n",
      "checkpoints/i590_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 591...  Training loss: 2.5661...  0.8528 sec/batch\n",
      "checkpoints/i591_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 592...  Training loss: 2.5582...  0.8770 sec/batch\n",
      "checkpoints/i592_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 593...  Training loss: 2.5478...  0.8599 sec/batch\n",
      "checkpoints/i593_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 594...  Training loss: 2.5568...  0.8482 sec/batch\n",
      "checkpoints/i594_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 595...  Training loss: 2.5257...  0.8598 sec/batch\n",
      "checkpoints/i595_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 596...  Training loss: 2.5388...  0.8532 sec/batch\n",
      "checkpoints/i596_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 597...  Training loss: 2.5499...  0.8542 sec/batch\n",
      "checkpoints/i597_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 598...  Training loss: 2.5353...  0.8601 sec/batch\n",
      "checkpoints/i598_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 599...  Training loss: 2.5380...  0.8889 sec/batch\n",
      "checkpoints/i599_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 600...  Training loss: 2.5645...  0.8559 sec/batch\n",
      "checkpoints/i600_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 601...  Training loss: 2.5608...  0.8853 sec/batch\n",
      "checkpoints/i601_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 602...  Training loss: 2.5505...  0.8598 sec/batch\n",
      "checkpoints/i602_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 603...  Training loss: 2.5396...  0.8607 sec/batch\n",
      "checkpoints/i603_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 604...  Training loss: 2.5516...  0.8572 sec/batch\n",
      "checkpoints/i604_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 605...  Training loss: 2.5160...  0.8587 sec/batch\n",
      "checkpoints/i605_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 606...  Training loss: 2.5406...  0.8668 sec/batch\n",
      "checkpoints/i606_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 607...  Training loss: 2.5155...  0.8821 sec/batch\n",
      "checkpoints/i607_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 608...  Training loss: 2.5432...  0.8745 sec/batch\n",
      "checkpoints/i608_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 609...  Training loss: 2.5137...  0.8602 sec/batch\n",
      "checkpoints/i609_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 610...  Training loss: 2.5170...  0.8573 sec/batch\n",
      "checkpoints/i610_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 611...  Training loss: 2.5116...  0.8502 sec/batch\n",
      "checkpoints/i611_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 612...  Training loss: 2.5260...  0.8562 sec/batch\n",
      "checkpoints/i612_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 613...  Training loss: 2.5181...  0.8766 sec/batch\n",
      "checkpoints/i613_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 614...  Training loss: 2.5310...  0.8898 sec/batch\n",
      "checkpoints/i614_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 615...  Training loss: 2.5229...  0.8683 sec/batch\n",
      "checkpoints/i615_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 616...  Training loss: 2.5282...  0.8510 sec/batch\n",
      "checkpoints/i616_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 617...  Training loss: 2.5275...  0.8616 sec/batch\n",
      "checkpoints/i617_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 618...  Training loss: 2.4946...  0.8594 sec/batch\n",
      "checkpoints/i618_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 619...  Training loss: 2.5072...  0.8705 sec/batch\n",
      "checkpoints/i619_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 620...  Training loss: 2.4760...  0.8664 sec/batch\n",
      "checkpoints/i620_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 621...  Training loss: 2.5186...  0.8779 sec/batch\n",
      "checkpoints/i621_l512.ckpt\n",
      "Epoch: 7/10...  Training Step: 622...  Training loss: 2.5105...  0.8724 sec/batch\n",
      "checkpoints/i622_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [08:58<03:50, 76.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10...  Training Step: 623...  Training loss: 2.5179...  0.8554 sec/batch\n",
      "checkpoints/i623_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 624...  Training loss: 2.5816...  0.8598 sec/batch\n",
      "checkpoints/i624_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 625...  Training loss: 2.5166...  0.8689 sec/batch\n",
      "checkpoints/i625_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 626...  Training loss: 2.5144...  0.8544 sec/batch\n",
      "checkpoints/i626_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 627...  Training loss: 2.5187...  0.8747 sec/batch\n",
      "checkpoints/i627_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 628...  Training loss: 2.5111...  0.8735 sec/batch\n",
      "checkpoints/i628_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 629...  Training loss: 2.5256...  0.8549 sec/batch\n",
      "checkpoints/i629_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 630...  Training loss: 2.5248...  0.8608 sec/batch\n",
      "checkpoints/i630_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 631...  Training loss: 2.5094...  0.8552 sec/batch\n",
      "checkpoints/i631_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 632...  Training loss: 2.5283...  0.8798 sec/batch\n",
      "checkpoints/i632_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 633...  Training loss: 2.4978...  0.8788 sec/batch\n",
      "checkpoints/i633_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 634...  Training loss: 2.4839...  0.8618 sec/batch\n",
      "checkpoints/i634_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 635...  Training loss: 2.4912...  0.8546 sec/batch\n",
      "checkpoints/i635_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 636...  Training loss: 2.4922...  0.8599 sec/batch\n",
      "checkpoints/i636_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 637...  Training loss: 2.4874...  0.8538 sec/batch\n",
      "checkpoints/i637_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 638...  Training loss: 2.5171...  0.8642 sec/batch\n",
      "checkpoints/i638_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 639...  Training loss: 2.5144...  0.8722 sec/batch\n",
      "checkpoints/i639_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 640...  Training loss: 2.4676...  0.8664 sec/batch\n",
      "checkpoints/i640_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 641...  Training loss: 2.5086...  0.8534 sec/batch\n",
      "checkpoints/i641_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 642...  Training loss: 2.5093...  0.8528 sec/batch\n",
      "checkpoints/i642_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 643...  Training loss: 2.4790...  0.8600 sec/batch\n",
      "checkpoints/i643_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 644...  Training loss: 2.4871...  0.8629 sec/batch\n",
      "checkpoints/i644_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 645...  Training loss: 2.4858...  0.8632 sec/batch\n",
      "checkpoints/i645_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 646...  Training loss: 2.4654...  0.8758 sec/batch\n",
      "checkpoints/i646_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 647...  Training loss: 2.4875...  0.8705 sec/batch\n",
      "checkpoints/i647_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 648...  Training loss: 2.4828...  0.8582 sec/batch\n",
      "checkpoints/i648_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 649...  Training loss: 2.4832...  0.8600 sec/batch\n",
      "checkpoints/i649_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 650...  Training loss: 2.4792...  0.8556 sec/batch\n",
      "checkpoints/i650_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 651...  Training loss: 2.4996...  0.8506 sec/batch\n",
      "checkpoints/i651_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 652...  Training loss: 2.5074...  0.8543 sec/batch\n",
      "checkpoints/i652_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 653...  Training loss: 2.5069...  0.8504 sec/batch\n",
      "checkpoints/i653_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 654...  Training loss: 2.4772...  0.8453 sec/batch\n",
      "checkpoints/i654_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 655...  Training loss: 2.4825...  0.8538 sec/batch\n",
      "checkpoints/i655_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 656...  Training loss: 2.4887...  0.8530 sec/batch\n",
      "checkpoints/i656_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 657...  Training loss: 2.4735...  0.8439 sec/batch\n",
      "checkpoints/i657_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 658...  Training loss: 2.4879...  0.8612 sec/batch\n",
      "checkpoints/i658_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 659...  Training loss: 2.4717...  0.8664 sec/batch\n",
      "checkpoints/i659_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 660...  Training loss: 2.4898...  0.8754 sec/batch\n",
      "checkpoints/i660_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 661...  Training loss: 2.4646...  0.8558 sec/batch\n",
      "checkpoints/i661_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 662...  Training loss: 2.5126...  0.8613 sec/batch\n",
      "checkpoints/i662_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 663...  Training loss: 2.5008...  0.8567 sec/batch\n",
      "checkpoints/i663_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 664...  Training loss: 2.5026...  0.8608 sec/batch\n",
      "checkpoints/i664_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 665...  Training loss: 2.5072...  0.8765 sec/batch\n",
      "checkpoints/i665_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 666...  Training loss: 2.4854...  0.8762 sec/batch\n",
      "checkpoints/i666_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 667...  Training loss: 2.4986...  0.8562 sec/batch\n",
      "checkpoints/i667_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 668...  Training loss: 2.5075...  0.8695 sec/batch\n",
      "checkpoints/i668_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 669...  Training loss: 2.5149...  0.8628 sec/batch\n",
      "checkpoints/i669_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 670...  Training loss: 2.5133...  0.8784 sec/batch\n",
      "checkpoints/i670_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 671...  Training loss: 2.4857...  0.8608 sec/batch\n",
      "checkpoints/i671_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 672...  Training loss: 2.5012...  0.8721 sec/batch\n",
      "checkpoints/i672_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 673...  Training loss: 2.4863...  0.8578 sec/batch\n",
      "checkpoints/i673_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 674...  Training loss: 2.4729...  0.8585 sec/batch\n",
      "checkpoints/i674_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 675...  Training loss: 2.4733...  0.8616 sec/batch\n",
      "checkpoints/i675_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 676...  Training loss: 2.4906...  0.8989 sec/batch\n",
      "checkpoints/i676_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 677...  Training loss: 2.4962...  0.8738 sec/batch\n",
      "checkpoints/i677_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 678...  Training loss: 2.4726...  0.8612 sec/batch\n",
      "checkpoints/i678_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 679...  Training loss: 2.4984...  0.8654 sec/batch\n",
      "checkpoints/i679_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 680...  Training loss: 2.4897...  0.8586 sec/batch\n",
      "checkpoints/i680_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 681...  Training loss: 2.4806...  0.8654 sec/batch\n",
      "checkpoints/i681_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 682...  Training loss: 2.4724...  0.8839 sec/batch\n",
      "checkpoints/i682_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 683...  Training loss: 2.4870...  0.8690 sec/batch\n",
      "checkpoints/i683_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 684...  Training loss: 2.4478...  0.8572 sec/batch\n",
      "checkpoints/i684_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 685...  Training loss: 2.4763...  0.8659 sec/batch\n",
      "checkpoints/i685_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 686...  Training loss: 2.4917...  0.8604 sec/batch\n",
      "checkpoints/i686_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 687...  Training loss: 2.4667...  0.8614 sec/batch\n",
      "checkpoints/i687_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 688...  Training loss: 2.4811...  0.8949 sec/batch\n",
      "checkpoints/i688_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 689...  Training loss: 2.5060...  0.8835 sec/batch\n",
      "checkpoints/i689_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 690...  Training loss: 2.4890...  0.8578 sec/batch\n",
      "checkpoints/i690_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 691...  Training loss: 2.5040...  0.8521 sec/batch\n",
      "checkpoints/i691_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 692...  Training loss: 2.4881...  0.8564 sec/batch\n",
      "checkpoints/i692_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 693...  Training loss: 2.4977...  0.8650 sec/batch\n",
      "checkpoints/i693_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 694...  Training loss: 2.4711...  0.8720 sec/batch\n",
      "checkpoints/i694_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 695...  Training loss: 2.5073...  0.8572 sec/batch\n",
      "checkpoints/i695_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 696...  Training loss: 2.4552...  0.8598 sec/batch\n",
      "checkpoints/i696_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 697...  Training loss: 2.4884...  0.8486 sec/batch\n",
      "checkpoints/i697_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 698...  Training loss: 2.4611...  0.8635 sec/batch\n",
      "checkpoints/i698_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 699...  Training loss: 2.4661...  0.8508 sec/batch\n",
      "checkpoints/i699_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 700...  Training loss: 2.4616...  0.8566 sec/batch\n",
      "checkpoints/i700_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 701...  Training loss: 2.4765...  0.8716 sec/batch\n",
      "checkpoints/i701_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 702...  Training loss: 2.4690...  0.8754 sec/batch\n",
      "checkpoints/i702_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 703...  Training loss: 2.4815...  0.8723 sec/batch\n",
      "checkpoints/i703_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 704...  Training loss: 2.4754...  0.8666 sec/batch\n",
      "checkpoints/i704_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 705...  Training loss: 2.4595...  0.8604 sec/batch\n",
      "checkpoints/i705_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 706...  Training loss: 2.4649...  0.8741 sec/batch\n",
      "checkpoints/i706_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 707...  Training loss: 2.4524...  0.8587 sec/batch\n",
      "checkpoints/i707_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 708...  Training loss: 2.4446...  0.8744 sec/batch\n",
      "checkpoints/i708_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 709...  Training loss: 2.4282...  0.8883 sec/batch\n",
      "checkpoints/i709_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 710...  Training loss: 2.4698...  0.8645 sec/batch\n",
      "checkpoints/i710_l512.ckpt\n",
      "Epoch: 8/10...  Training Step: 711...  Training loss: 2.4583...  0.8600 sec/batch\n",
      "checkpoints/i711_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [10:15<02:33, 76.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10...  Training Step: 712...  Training loss: 2.4660...  0.8657 sec/batch\n",
      "checkpoints/i712_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 713...  Training loss: 2.5317...  0.8581 sec/batch\n",
      "checkpoints/i713_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 714...  Training loss: 2.4589...  0.8350 sec/batch\n",
      "checkpoints/i714_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 715...  Training loss: 2.4713...  0.8583 sec/batch\n",
      "checkpoints/i715_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 716...  Training loss: 2.4775...  0.8545 sec/batch\n",
      "checkpoints/i716_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 717...  Training loss: 2.4621...  0.8531 sec/batch\n",
      "checkpoints/i717_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 718...  Training loss: 2.4691...  0.8998 sec/batch\n",
      "checkpoints/i718_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 719...  Training loss: 2.4746...  0.8539 sec/batch\n",
      "checkpoints/i719_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 720...  Training loss: 2.4563...  0.8634 sec/batch\n",
      "checkpoints/i720_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 721...  Training loss: 2.4793...  0.8742 sec/batch\n",
      "checkpoints/i721_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 722...  Training loss: 2.4453...  0.8580 sec/batch\n",
      "checkpoints/i722_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 723...  Training loss: 2.4399...  0.8537 sec/batch\n",
      "checkpoints/i723_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 724...  Training loss: 2.4502...  0.8810 sec/batch\n",
      "checkpoints/i724_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 725...  Training loss: 2.4407...  0.8880 sec/batch\n",
      "checkpoints/i725_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 726...  Training loss: 2.4407...  0.8597 sec/batch\n",
      "checkpoints/i726_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 727...  Training loss: 2.4572...  0.8553 sec/batch\n",
      "checkpoints/i727_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 728...  Training loss: 2.4707...  0.8646 sec/batch\n",
      "checkpoints/i728_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 729...  Training loss: 2.4173...  0.8435 sec/batch\n",
      "checkpoints/i729_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 730...  Training loss: 2.4571...  0.8535 sec/batch\n",
      "checkpoints/i730_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 731...  Training loss: 2.4565...  0.8657 sec/batch\n",
      "checkpoints/i731_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 732...  Training loss: 2.4280...  0.8562 sec/batch\n",
      "checkpoints/i732_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 733...  Training loss: 2.4314...  0.8724 sec/batch\n",
      "checkpoints/i733_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 734...  Training loss: 2.4366...  0.8530 sec/batch\n",
      "checkpoints/i734_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 735...  Training loss: 2.4139...  0.8615 sec/batch\n",
      "checkpoints/i735_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 736...  Training loss: 2.4329...  0.8635 sec/batch\n",
      "checkpoints/i736_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 737...  Training loss: 2.4387...  0.8563 sec/batch\n",
      "checkpoints/i737_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 738...  Training loss: 2.4421...  0.8566 sec/batch\n",
      "checkpoints/i738_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 739...  Training loss: 2.4333...  0.8917 sec/batch\n",
      "checkpoints/i739_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 740...  Training loss: 2.4539...  0.8541 sec/batch\n",
      "checkpoints/i740_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 741...  Training loss: 2.4597...  0.8576 sec/batch\n",
      "checkpoints/i741_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 742...  Training loss: 2.4662...  0.8475 sec/batch\n",
      "checkpoints/i742_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 743...  Training loss: 2.4300...  0.8566 sec/batch\n",
      "checkpoints/i743_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 744...  Training loss: 2.4357...  0.8562 sec/batch\n",
      "checkpoints/i744_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 745...  Training loss: 2.4408...  0.8555 sec/batch\n",
      "checkpoints/i745_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 746...  Training loss: 2.4182...  0.8573 sec/batch\n",
      "checkpoints/i746_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 747...  Training loss: 2.4376...  0.8904 sec/batch\n",
      "checkpoints/i747_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 748...  Training loss: 2.4375...  0.8719 sec/batch\n",
      "checkpoints/i748_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 749...  Training loss: 2.4517...  0.8629 sec/batch\n",
      "checkpoints/i749_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 750...  Training loss: 2.4188...  0.8607 sec/batch\n",
      "checkpoints/i750_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 751...  Training loss: 2.4799...  0.8554 sec/batch\n",
      "checkpoints/i751_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 752...  Training loss: 2.4619...  0.8562 sec/batch\n",
      "checkpoints/i752_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 753...  Training loss: 2.4633...  0.8579 sec/batch\n",
      "checkpoints/i753_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 754...  Training loss: 2.4673...  0.8600 sec/batch\n",
      "checkpoints/i754_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 755...  Training loss: 2.4523...  0.8786 sec/batch\n",
      "checkpoints/i755_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 756...  Training loss: 2.4788...  0.8573 sec/batch\n",
      "checkpoints/i756_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 757...  Training loss: 2.4989...  0.8561 sec/batch\n",
      "checkpoints/i757_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 758...  Training loss: 2.4869...  0.8581 sec/batch\n",
      "checkpoints/i758_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 759...  Training loss: 2.5381...  0.8587 sec/batch\n",
      "checkpoints/i759_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 760...  Training loss: 2.5334...  0.8471 sec/batch\n",
      "checkpoints/i760_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 761...  Training loss: 2.5283...  0.8829 sec/batch\n",
      "checkpoints/i761_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 762...  Training loss: 2.5069...  0.8625 sec/batch\n",
      "checkpoints/i762_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 763...  Training loss: 2.4662...  0.8555 sec/batch\n",
      "checkpoints/i763_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 764...  Training loss: 2.4740...  0.8600 sec/batch\n",
      "checkpoints/i764_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 765...  Training loss: 2.4884...  0.8549 sec/batch\n",
      "checkpoints/i765_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 766...  Training loss: 2.4939...  0.8600 sec/batch\n",
      "checkpoints/i766_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 767...  Training loss: 2.4832...  0.8575 sec/batch\n",
      "checkpoints/i767_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 768...  Training loss: 2.5047...  0.8906 sec/batch\n",
      "checkpoints/i768_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 769...  Training loss: 2.4963...  0.8615 sec/batch\n",
      "checkpoints/i769_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 770...  Training loss: 2.4710...  0.8547 sec/batch\n",
      "checkpoints/i770_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 771...  Training loss: 2.4644...  0.8609 sec/batch\n",
      "checkpoints/i771_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 772...  Training loss: 2.4715...  0.8555 sec/batch\n",
      "checkpoints/i772_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 773...  Training loss: 2.4293...  0.8732 sec/batch\n",
      "checkpoints/i773_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 774...  Training loss: 2.4576...  0.8640 sec/batch\n",
      "checkpoints/i774_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 775...  Training loss: 2.4577...  0.8555 sec/batch\n",
      "checkpoints/i775_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 776...  Training loss: 2.4473...  0.8579 sec/batch\n",
      "checkpoints/i776_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 777...  Training loss: 2.4514...  0.8607 sec/batch\n",
      "checkpoints/i777_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 778...  Training loss: 2.4832...  0.8561 sec/batch\n",
      "checkpoints/i778_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 779...  Training loss: 2.4675...  0.8651 sec/batch\n",
      "checkpoints/i779_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 780...  Training loss: 2.4596...  0.8812 sec/batch\n",
      "checkpoints/i780_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 781...  Training loss: 2.4522...  0.8812 sec/batch\n",
      "checkpoints/i781_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 782...  Training loss: 2.4662...  0.8620 sec/batch\n",
      "checkpoints/i782_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 783...  Training loss: 2.4313...  0.8583 sec/batch\n",
      "checkpoints/i783_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 784...  Training loss: 2.4620...  0.8545 sec/batch\n",
      "checkpoints/i784_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 785...  Training loss: 2.4136...  0.8580 sec/batch\n",
      "checkpoints/i785_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 786...  Training loss: 2.4422...  0.8702 sec/batch\n",
      "checkpoints/i786_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 787...  Training loss: 2.4270...  0.8914 sec/batch\n",
      "checkpoints/i787_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 788...  Training loss: 2.4242...  0.8650 sec/batch\n",
      "checkpoints/i788_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 789...  Training loss: 2.4251...  0.8539 sec/batch\n",
      "checkpoints/i789_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 790...  Training loss: 2.4409...  0.8637 sec/batch\n",
      "checkpoints/i790_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 791...  Training loss: 2.4265...  0.8650 sec/batch\n",
      "checkpoints/i791_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 792...  Training loss: 2.4386...  0.8637 sec/batch\n",
      "checkpoints/i792_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 793...  Training loss: 2.4349...  0.8641 sec/batch\n",
      "checkpoints/i793_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 794...  Training loss: 2.4283...  0.8820 sec/batch\n",
      "checkpoints/i794_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 795...  Training loss: 2.4313...  0.8663 sec/batch\n",
      "checkpoints/i795_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 796...  Training loss: 2.4102...  0.8524 sec/batch\n",
      "checkpoints/i796_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 797...  Training loss: 2.4113...  0.8545 sec/batch\n",
      "checkpoints/i797_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 798...  Training loss: 2.3880...  0.8506 sec/batch\n",
      "checkpoints/i798_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 799...  Training loss: 2.4293...  0.8578 sec/batch\n",
      "checkpoints/i799_l512.ckpt\n",
      "Epoch: 9/10...  Training Step: 800...  Training loss: 2.4200...  0.8832 sec/batch\n",
      "checkpoints/i800_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [11:32<01:16, 76.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10...  Training Step: 801...  Training loss: 2.4285...  0.9020 sec/batch\n",
      "checkpoints/i801_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 802...  Training loss: 2.4999...  0.8526 sec/batch\n",
      "checkpoints/i802_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 803...  Training loss: 2.4356...  0.8579 sec/batch\n",
      "checkpoints/i803_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 804...  Training loss: 2.4329...  0.8731 sec/batch\n",
      "checkpoints/i804_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 805...  Training loss: 2.4364...  0.8574 sec/batch\n",
      "checkpoints/i805_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 806...  Training loss: 2.4256...  0.8595 sec/batch\n",
      "checkpoints/i806_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 807...  Training loss: 2.4342...  0.8667 sec/batch\n",
      "checkpoints/i807_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 808...  Training loss: 2.4470...  0.8839 sec/batch\n",
      "checkpoints/i808_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 809...  Training loss: 2.4173...  0.8755 sec/batch\n",
      "checkpoints/i809_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 810...  Training loss: 2.4327...  0.8560 sec/batch\n",
      "checkpoints/i810_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 811...  Training loss: 2.4091...  0.8600 sec/batch\n",
      "checkpoints/i811_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 812...  Training loss: 2.4070...  0.8598 sec/batch\n",
      "checkpoints/i812_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 813...  Training loss: 2.4005...  0.8546 sec/batch\n",
      "checkpoints/i813_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 814...  Training loss: 2.4013...  0.8598 sec/batch\n",
      "checkpoints/i814_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 815...  Training loss: 2.4121...  0.8582 sec/batch\n",
      "checkpoints/i815_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 816...  Training loss: 2.4280...  0.8705 sec/batch\n",
      "checkpoints/i816_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 817...  Training loss: 2.4278...  0.8748 sec/batch\n",
      "checkpoints/i817_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 818...  Training loss: 2.3831...  0.8546 sec/batch\n",
      "checkpoints/i818_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 819...  Training loss: 2.4139...  0.8573 sec/batch\n",
      "checkpoints/i819_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 820...  Training loss: 2.4225...  0.8652 sec/batch\n",
      "checkpoints/i820_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 821...  Training loss: 2.3964...  0.8459 sec/batch\n",
      "checkpoints/i821_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 822...  Training loss: 2.3944...  0.8586 sec/batch\n",
      "checkpoints/i822_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 823...  Training loss: 2.4008...  0.8602 sec/batch\n",
      "checkpoints/i823_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 824...  Training loss: 2.3786...  0.8545 sec/batch\n",
      "checkpoints/i824_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 825...  Training loss: 2.3999...  0.8961 sec/batch\n",
      "checkpoints/i825_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 826...  Training loss: 2.4030...  0.8595 sec/batch\n",
      "checkpoints/i826_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 827...  Training loss: 2.4010...  0.8577 sec/batch\n",
      "checkpoints/i827_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 828...  Training loss: 2.3897...  0.8596 sec/batch\n",
      "checkpoints/i828_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 829...  Training loss: 2.4068...  0.8493 sec/batch\n",
      "checkpoints/i829_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 830...  Training loss: 2.4183...  0.8653 sec/batch\n",
      "checkpoints/i830_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 831...  Training loss: 2.4250...  0.8825 sec/batch\n",
      "checkpoints/i831_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 832...  Training loss: 2.3940...  0.8481 sec/batch\n",
      "checkpoints/i832_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 833...  Training loss: 2.3944...  0.8538 sec/batch\n",
      "checkpoints/i833_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 834...  Training loss: 2.4011...  0.8735 sec/batch\n",
      "checkpoints/i834_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 835...  Training loss: 2.3778...  0.8605 sec/batch\n",
      "checkpoints/i835_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 836...  Training loss: 2.4100...  0.8766 sec/batch\n",
      "checkpoints/i836_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 837...  Training loss: 2.3906...  0.8885 sec/batch\n",
      "checkpoints/i837_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 838...  Training loss: 2.4079...  0.8875 sec/batch\n",
      "checkpoints/i838_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 839...  Training loss: 2.3814...  0.8667 sec/batch\n",
      "checkpoints/i839_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 840...  Training loss: 2.4319...  0.8521 sec/batch\n",
      "checkpoints/i840_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 841...  Training loss: 2.4043...  0.8575 sec/batch\n",
      "checkpoints/i841_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 842...  Training loss: 2.4176...  0.8611 sec/batch\n",
      "checkpoints/i842_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 843...  Training loss: 2.4283...  0.8518 sec/batch\n",
      "checkpoints/i843_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 844...  Training loss: 2.3939...  0.8684 sec/batch\n",
      "checkpoints/i844_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 845...  Training loss: 2.4150...  0.8502 sec/batch\n",
      "checkpoints/i845_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 846...  Training loss: 2.4135...  0.8502 sec/batch\n",
      "checkpoints/i846_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 847...  Training loss: 2.4297...  0.8553 sec/batch\n",
      "checkpoints/i847_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 848...  Training loss: 2.4207...  0.8584 sec/batch\n",
      "checkpoints/i848_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 849...  Training loss: 2.4019...  0.8515 sec/batch\n",
      "checkpoints/i849_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 850...  Training loss: 2.4126...  0.8582 sec/batch\n",
      "checkpoints/i850_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 851...  Training loss: 2.4050...  0.8481 sec/batch\n",
      "checkpoints/i851_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 852...  Training loss: 2.3887...  0.8471 sec/batch\n",
      "checkpoints/i852_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 853...  Training loss: 2.3839...  0.8779 sec/batch\n",
      "checkpoints/i853_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 854...  Training loss: 2.4011...  0.8529 sec/batch\n",
      "checkpoints/i854_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 855...  Training loss: 2.4068...  0.8503 sec/batch\n",
      "checkpoints/i855_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 856...  Training loss: 2.3955...  0.8581 sec/batch\n",
      "checkpoints/i856_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 857...  Training loss: 2.4175...  0.8528 sec/batch\n",
      "checkpoints/i857_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 858...  Training loss: 2.4145...  0.8598 sec/batch\n",
      "checkpoints/i858_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 859...  Training loss: 2.4048...  0.8614 sec/batch\n",
      "checkpoints/i859_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 860...  Training loss: 2.3948...  0.8764 sec/batch\n",
      "checkpoints/i860_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 861...  Training loss: 2.4044...  0.8570 sec/batch\n",
      "checkpoints/i861_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 862...  Training loss: 2.3665...  0.8587 sec/batch\n",
      "checkpoints/i862_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 863...  Training loss: 2.3988...  0.8621 sec/batch\n",
      "checkpoints/i863_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 864...  Training loss: 2.4009...  0.8511 sec/batch\n",
      "checkpoints/i864_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 865...  Training loss: 2.3895...  0.8563 sec/batch\n",
      "checkpoints/i865_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 866...  Training loss: 2.3950...  0.8560 sec/batch\n",
      "checkpoints/i866_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 867...  Training loss: 2.4251...  0.8652 sec/batch\n",
      "checkpoints/i867_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 868...  Training loss: 2.4015...  0.8700 sec/batch\n",
      "checkpoints/i868_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 869...  Training loss: 2.4068...  0.8835 sec/batch\n",
      "checkpoints/i869_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 870...  Training loss: 2.3987...  0.8617 sec/batch\n",
      "checkpoints/i870_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 871...  Training loss: 2.4086...  0.8495 sec/batch\n",
      "checkpoints/i871_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 872...  Training loss: 2.3804...  0.8544 sec/batch\n",
      "checkpoints/i872_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 873...  Training loss: 2.4112...  0.8534 sec/batch\n",
      "checkpoints/i873_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 874...  Training loss: 2.3585...  0.8728 sec/batch\n",
      "checkpoints/i874_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 875...  Training loss: 2.3963...  0.8642 sec/batch\n",
      "checkpoints/i875_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 876...  Training loss: 2.3723...  0.8528 sec/batch\n",
      "checkpoints/i876_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 877...  Training loss: 2.3738...  0.8561 sec/batch\n",
      "checkpoints/i877_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 878...  Training loss: 2.3744...  0.8667 sec/batch\n",
      "checkpoints/i878_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 879...  Training loss: 2.3885...  0.8557 sec/batch\n",
      "checkpoints/i879_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 880...  Training loss: 2.3799...  0.8462 sec/batch\n",
      "checkpoints/i880_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 881...  Training loss: 2.3879...  0.8492 sec/batch\n",
      "checkpoints/i881_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 882...  Training loss: 2.3874...  0.8709 sec/batch\n",
      "checkpoints/i882_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 883...  Training loss: 2.3899...  0.8525 sec/batch\n",
      "checkpoints/i883_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 884...  Training loss: 2.3780...  0.8728 sec/batch\n",
      "checkpoints/i884_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 885...  Training loss: 2.3691...  0.8510 sec/batch\n",
      "checkpoints/i885_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 886...  Training loss: 2.3656...  0.8552 sec/batch\n",
      "checkpoints/i886_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 887...  Training loss: 2.3342...  0.8539 sec/batch\n",
      "checkpoints/i887_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 888...  Training loss: 2.3868...  0.8593 sec/batch\n",
      "checkpoints/i888_l512.ckpt\n",
      "Epoch: 10/10...  Training Step: 889...  Training loss: 2.3676...  0.8640 sec/batch\n",
      "checkpoints/i889_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [12:49<00:00, 76.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10...  Training Step: 890...  Training loss: 2.3879...  0.8618 sec/batch\n",
      "checkpoints/i890_l512.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 10\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    counter = 0\n",
    "    for e in tqdm(range(epochs)):\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            end = time.time()\n",
    "            print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                  'Training Step: {}... '.format(counter),\n",
    "                  'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "            print(\"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"Сегодня 17 октября 2018 года\"):\n",
    "    samples = [c for c in prime]\n",
    "    model = CharRNN(len(vocab), lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.prediction, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_checkpoint_path: \"checkpoints/i890_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i200_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i400_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i600_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i800_l512.ckpt\"\n",
       "all_model_checkpoint_paths: \"checkpoints/i890_l512.ckpt\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i890_l512.ckpt\n",
      "Сегодня 17 октября 2018 года в дем \n",
      "протет поледани, стаховить в нем, \n",
      "потерет, \n",
      "поднетье в дули, кок небель \n",
      "нам на стратали нет\n"
     ]
    }
   ],
   "source": [
    "samp = sample('checkpoints/i890_l512.ckpt',100, lstm_size, len(vocab))\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:conda]",
   "language": "python",
   "name": "conda-env-conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
